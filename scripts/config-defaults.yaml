# training settings
nepochs:
  value: 1000
train_size:
  value: 1000
batch_size:
  value: 50
chi_frequency:
  desc: How often to calculate chi-score for train and test.
  value: 5
seed:
  value: 7

# training features
lambda_:
  value: 0.005844921623203759
training_balance:
  desc: How many more times to train discriminator than generator.
  value: 2
true_label_smooth:
  desc: Multiply true labels by this to smooth discriminator's labels.
  value: 0.9

# architecture
lrelu:
  value: 0.2991161912395133
dropout:
  value: 0.44053850596844424
latent_dims:
  value: 100
g_layers:
  desc: Number of channels in the hidden layers for the generator.
  value: [25600, 512, 256]
complexity_0:
  value: 1
complexity_1:
  value: 1
complexity_2:
  value: 2
d_layers:
  desc: Number of channels in the hidden layers for the discriminator.
  value: [64, 128, 256]


# Adam parameters
learning_rate:
  value: 0.00013367626823798716
beta_1:
  value: 0.22693882275467836
beta_2:
  value: 0.999
clipnorm:
  value:
global_clipnorm:
  value:
use_ema:
  desc: Use exponential moving average in training, causes issues when re-loading weights.
  value: False # only set to true if not loading weights
ema_momentum:
  value: 0.9
ema_overwrite_frequency:
  desc: How often to overwrite weights with ema.
  value: 1




# for linux cluster
#Â export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soge-home/users/spet5107/micromamba/envs/tensorflow/lib